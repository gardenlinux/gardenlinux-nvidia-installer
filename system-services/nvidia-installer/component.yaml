version: 1.5.0
description: system pod for installing nvidia gpu drivers in the host operating system

ignoreVersion:
- 184.0.0-450.80.02-sap2
- 184.0.0-450.80.02-sap3
- 318.8.0-440.82-sap1
- 318.8.0-450.80.02-sap1
- 318.8.0-470.82.01-sap1
- 318.8.0-sap2
- 318.8.0-sap3

context:
  driverVersion:
    - '440.82'
    - '450.80.02'
    - '470.82.01'
  gardenLinuxVersion:
    # - '184.0.0' - TODO revert when the GL dev image is rolled into this build
    - '318.8.0'
  imageName: com.sap.ai/nvidia-installer-{gardenLinuxVersion}-{driverVersion}{image_suffix}

steps:
  jenkins:
    type: jenkinsJob
    job: aicore/nvidia-installer
  build:
    type: parameterized
    parameters:
      - driverVersion: '{driverVersion}'
      - gardenLinuxVersion: '{gardenLinuxVersion}'
    step:
      type: dockerbuild
      imageName: '{imageName}'
      dockerfile: Dockerfile
      buildArgs:
        DRIVER_VERSION: '{driverVersion}'
        GARDENLINUX_VERSION: '{gardenLinuxVersion}'
        GIT_COMMIT: '{builtin.git_commit}'
        GIT_TAG: '{builtin.version}'
        GIT_TREE_STATE: '{builtin.git_tree_state}'
  lint:
    type: dockerRun
    dockerfile: test.Dockerfile
    shell: /bin/bash
    env:
      ARTIFACTS: /repo
    commands:
    - helm lint helm --set targetInfrastructure.gardener=true > "${{ARTIFACTS}}"/helm-lint.out
    - lint_exit_code=$?
    - cat "${{ARTIFACTS}}"/helm-lint.out
    - echo \"helm lint exit code was ${{lint_exit_code}}\"
    - if [[ ${{lint_exit_code}} != 0 ]]; then exit ${{lint_exit_code}}; fi

    - shellcheck resources/* > "${{ARTIFACTS}}"/shellcheck.out
    - shellcheck_exit_code=$?
    - cat "${{ARTIFACTS}}"/shellcheck.out
    - echo \"shellcheck exit code was ${{shellcheck_exit_code}}\"
    - exit ${{shellcheck_exit_code}}
  unit:
    type: dockerRun
    dockerfile: test.Dockerfile
    shell: /bin/bash
    env:
      ARTIFACTS: /repo
    commands:
    - helm template nvidia-installer helm --set targetInfrastructure.gardener=true
      > "${{ARTIFACTS}}"/nvidia-installer.yaml
    - template_exit_code=$?
    - cat "${{ARTIFACTS}}"/nvidia-installer.yaml
    - echo \"helm template exit code was ${{template_exit_code}}\"
    - if [[ ${{template_exit_code}} != 0 ]]; then exit ${{template_exit_code}}; fi

    - kubeconform --kubernetes-version 1.21.0 --strict --summary --verbose "${{ARTIFACTS}}"/nvidia-installer.yaml
      > "${{ARTIFACTS}}"/kubeconform.out
    - kubeconform_exit_code=$?
    - cat "${{ARTIFACTS}}"/kubeconform.out
    - echo \"kubeconform exit code was ${{kubeconform_exit_code}}\"
    - exit ${{kubeconform_exit_code}}
  whitesource:
    type: whitesource

pipelines:
  local:
    build: build
  push-validation:
    build: jenkins
  main:
    build: jenkins
  release:
    build: jenkins

patch:
- file: .xmake.cfg
  regexp: version=.*
  replace: version={builtin.version}
- file: helm/Chart.yaml
  yaml_path: version
  replace: '{builtin.version}'
- file: helm/values.yaml
  regexp: 'installerTag: .*'
  replace: 'installerTag: {builtin.version}'
- file: wss-unified-agent.config
  regexp: projectVersion=.*
  replace: projectVersion={builtin.component_version}

dependencies:
- component: system-services/gardenlinux-dev
  patch:
  - file: Dockerfile
    regexp: FROM \S* AS builder
    replace: FROM {docker_registry}{imageName}:{builtin.version} AS builder
  - file: test.Dockerfile
    regexp: FROM \S*
    replace: FROM {docker_registry}{imageName}:{builtin.version}
  - file: Dockerfile
    regexp: ARG KERNEL_VERSION=.*
    replace: ARG KERNEL_VERSION={kernelVersion}
  - file: helm/values.yaml
    regexp: 'values: \[\".*\"\]'
    replace: 'values: ["{gardenlinuxVersion}"]'
