name: Complete Helm CI/CD
on:
  workflow_dispatch:
  pull_request:

env:
  CHART_PATH: ./tests

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Helm lint
        run: |
          helm lint ${{ env.CHART_PATH }}

  test:
    needs: lint
    runs-on: ubuntu-latest
    permissions:
      # This is required for requesting the JWT
      id-token: write
    steps:
      - uses: actions/checkout@v3

      - name: Authenticate to cluster
        id: kube_auth
        uses: gardener/cc-utils/.github/actions/kubernetes-auth@b7e4d874f30171964c5262a0bc20d644f4bcedba
        with:
          server: https://api.gpu-ci-test.gl-ai.shoot.canary.k8s-hana.ondemand.com 
          server-ca-discovery-url: https://discovery.ingress.garden.canary.k8s.ondemand.com/projects/gl-ai/shoots/8b446787-d656-48c1-813b-d2e3867e65a6/cluster-ca
          audience: gpu-ci-test
          service-account-name: ci-gpu-test-sa
          service-account-namespace: gpu-operator
          service-account-token-expiration: 600
      
      - name: Wait for cluster
        env:
          KUBECONFIG: kubeconfig.yaml
        run: |
          kubectl wait --for=condition=Ready nodes --all --timeout=300s
          kubectl get nodes

      - name: Install nvidia installer
        env:
          KUBECONFIG: kubeconfig.yaml
        run: |
          helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
          helm repo update
          helm upgrade --install -n gpu-operator gpu-operator nvidia/gpu-operator --values helm/gpu-operator-values.yaml --set driver.repository=ghcr.io/gardenlinux/gardenlinux-nvidia-installer/open

      - name: Wait until all the pods are up and running
        run: |
          sleep 5m

      - name: Install chart
        env:
          KUBECONFIG: kubeconfig.yaml
        run: |
          helm install test-release ${{ env.CHART_PATH }} \
            -n gpu-operator \
            --wait \
            --timeout 10m \
            --values ${{ env.CHART_PATH }}/values.yaml

      - name: Run Helm tests
        env:
          KUBECONFIG: kubeconfig.yaml
        id: helm-test
        run: |
          helm test test-release -n gpu-operator --logs 2>&1 | tee test-output.log
          echo "exit_code=$?" >> "$GITHUB_OUTPUT"

      - name: Debug on failure
        env:
          KUBECONFIG: kubeconfig.yaml
        if: failure()
        run: |
          echo "=== Helm Test Failed ==="
          kubectl get pods -n gpu-operator
          kubectl describe pods -l "app.kubernetes.io/instance=test-release"
          helm status test-release -n test-gpu-operator

      - name: Cleanup
        env:
          KUBECONFIG: kubeconfig.yaml
        if: always()
        run: |
          helm uninstall test-release -n gpu-operator || true
